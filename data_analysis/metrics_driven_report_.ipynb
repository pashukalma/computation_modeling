{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Prototyping metrics-driven report**"
      ],
      "metadata": {
        "id": "GNhWFdNcNetl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a metrics-driven report of trends and topics of interest, and how they shift over time"
      ],
      "metadata": {
        "id": "M-qcMwdqOJ6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "uK_oU-g9Osf4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' work with engagement data '''\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "import os\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "id": "l08oR5XbN3c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' perform basic data exploration '''\n",
        "df = pd.read_csv('engagements.csv')\n",
        "df.head()[:5]\n",
        "df.info()\n",
        "display(df.describe())"
      ],
      "metadata": {
        "id": "uoQGZJanOskK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Handle any missing values, convert data types if necessary,\n",
        "and extract relevant information (like date/time components)\n",
        "'''\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], format='mixed')\n",
        "df['date'] = df['timestamp'].dt.date\n",
        "df['media_caption'].fillna('', inplace=True)\n",
        "df['comment_text'].fillna('', inplace=True)\n",
        "display(df.head())\n",
        "display(df.info())"
      ],
      "metadata": {
        "id": "jVREA-U4N3gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Engagement trends analysis"
      ],
      "metadata": {
        "id": "TfyLAc92PV4M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elvGTvEJNX3a"
      },
      "outputs": [],
      "source": [
        "'''  Analyze engagement trends\n",
        "how engagement metrics (likes, comments, etc.) change over time, this could be\n",
        "time series analysis to identify daily, weekly, or monthly patterns\n",
        "\n",
        "Group the DataFrame by date, count the entries, reset the index,\n",
        "and sort by date to prepare for time series analysis.\n",
        "'''\n",
        "daily_engagement = df.groupby('date').size().reset_index(name='engagement_count')\n",
        "daily_engagement['date'] = pd.to_datetime(daily_engagement['date'])\n",
        "daily_engagement = daily_engagement.sort_values(by='date')\n",
        "display(daily_engagement.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "the weekly and monthly engagement by resampling the daily engagement data and\n",
        "then display the first few rows of the daily, weekly, and monthly engagement\n",
        "dataframes to verify the results\n",
        "'''\n",
        "weekly_engagement = daily_engagement.resample('W', on='date')[\n",
        "    'engagement_count'].sum().reset_index(name='weekly_engagement_count')\n",
        "monthly_engagement = daily_engagement.resample('M', on='date')[\n",
        "    'engagement_count'].sum().reset_index(name='monthly_engagement_count')\n",
        "\n",
        "print(\"Daily Engagement:\")\n",
        "display(daily_engagement.head())\n",
        "print(\"\\nWeekly Engagement:\")\n",
        "display(weekly_engagement.head())\n",
        "print(\"\\nMonthly Engagement:\")\n",
        "display(monthly_engagement.head())"
      ],
      "metadata": {
        "id": "lRptqKPcO-oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify topics of interest"
      ],
      "metadata": {
        "id": "vOEIjAQMQDRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "If the data includes post content or tags, perform text analysis\n",
        "(like topic modeling or keyword extraction) to identify popular themes\n",
        "\n",
        "Combine the text columns, clean the text by converting to lowercase,\n",
        "removing punctuation, and removing stop words, and then calculate word frequencies.\n",
        "'''\n",
        "\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "try:\n",
        "    stopwords.words('english')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "# 1. Combine the media_caption and comment_text columns\n",
        "df['combined_text'] = df['media_caption'] + ' ' + df['comment_text']\n",
        "\n",
        "# 2. Perform basic text cleaning\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['combined_text'].apply(clean_text)\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['cleaned_text'] = df['cleaned_text'].apply(\n",
        "    lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "# 3. Use a simple word frequency count to identify important terms\n",
        "word_counts = {}\n",
        "for text in df['cleaned_text']:\n",
        "    for word in text.split():\n",
        "        word_counts[word] = word_counts.get(word, 0) + 1\n",
        "\n",
        "# Sort words by frequency\n",
        "sorted_word_counts = sorted(\n",
        "    word_counts.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# Display the top 50 most frequent words\n",
        "print(\"Top 50 most frequent words:\")\n",
        "for word, count in sorted_word_counts[:50]:\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Display the first few rows with the new columns\n",
        "display(\n",
        "  df[['media_caption', 'comment_text', 'combined_text', 'cleaned_text']].head())"
      ],
      "metadata": {
        "id": "V-L5ZiApO-r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic Trends analysis"
      ],
      "metadata": {
        "id": "RaANmDtFQo4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Examine how the popularity of identified topics shifts over time\n",
        "\n",
        "Create a combined text column, define keywords for each topic, iterate through\n",
        "rows to create boolean topic columns, group by date to calculate daily popularity,\n",
        "convert date to datetime, and sort.\n",
        "'''\n",
        "df['combined_text'] = df['media_caption'] + ' ' + df['comment_text']\n",
        "\n",
        "topic_keywords = {\n",
        "    'brand_product': ['tree hut', 'scrub', 'butter', 'wash',\n",
        "                      'scent', 'skin', 'product', 'smell', 'body'],\n",
        "    'marketing_promotions': ['giveaway', 'contest', 'win', 'enter',\n",
        "                             'winners', 'tag', 'share', 'follow',\n",
        "                             'chance', 'promo', 'discount'],\n",
        "    'user_sentiment': ['love', 'good', 'great', 'amazing', 'help',\n",
        "                       'favorite', 'want', 'need', 'obsessed', 'repurchase']\n",
        "}\n",
        "\n",
        "for topic, keywords in topic_keywords.items():\n",
        "    df[topic] = df['combined_text'].apply(\n",
        "        lambda x: any(keyword in x.lower() for keyword in keywords))\n",
        "\n",
        "daily_topic_popularity = df.groupby('date')[\n",
        "    list(topic_keywords.keys())].mean().reset_index()\n",
        "daily_topic_popularity['date'] = pd.to_datetime(daily_topic_popularity['date'])\n",
        "daily_topic_popularity = daily_topic_popularity.sort_values(by='date')\n",
        "\n",
        "display(daily_topic_popularity.head())"
      ],
      "metadata": {
        "id": "iVwMQKnBP97g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Resample the daily topic popularity data to weekly and monthly\n",
        "frequencies by summing the popularity scores\n",
        "'''\n",
        "weekly_topic_popularity = daily_topic_popularity.resample(\n",
        "    'W', on='date')[list(topic_keywords.keys())].sum().reset_index()\n",
        "monthly_topic_popularity = daily_topic_popularity.resample(\n",
        "    'M', on='date')[list(topic_keywords.keys())].sum().reset_index()\n",
        "\n",
        "print(\"Weekly Topic Popularity:\")\n",
        "display(weekly_topic_popularity.head())\n",
        "print(\"\\nMonthly Topic Popularity:\")\n",
        "display(monthly_topic_popularity.head())"
      ],
      "metadata": {
        "id": "tY4DwuuzP9-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlate topics and engagement"
      ],
      "metadata": {
        "id": "kd7YzoEiRfoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Correlate topics and engagement\n",
        "\n",
        "Merge the daily engagement and daily topic popularity dataframes on the 'date'\n",
        "column, calculate the correlation matrix, and print\n",
        "'''\n",
        "daily_trends = pd.merge(daily_engagement, daily_topic_popularity, on='date')\n",
        "correlation_matrix = daily_trends.corr(numeric_only=True)\n",
        "print(\"Correlation matrix between engagement and topic popularity:\")\n",
        "display(correlation_matrix[['engagement_count']])"
      ],
      "metadata": {
        "id": "-7YZriNWRQ4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting daily engagement trends\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(daily_engagement['date'], daily_engagement['engagement_count'])\n",
        "plt.title('Daily Engagement Trends')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Engagement Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting weekly engagement trends\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(weekly_engagement['date'], weekly_engagement['weekly_engagement_count'])\n",
        "plt.title('Weekly Engagement Trends')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Weekly Engagement Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9aQVjPNRRQ7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plotting monthly engagement trends\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(monthly_engagement['date'], monthly_engagement['monthly_engagement_count'])\n",
        "plt.title('Monthly Engagement Trends')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Monthly Engagement Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting daily topic popularity trends\n",
        "plt.figure(figsize=(15, 6))\n",
        "for topic in topic_keywords.keys():\n",
        "    plt.plot(daily_topic_popularity['date'], daily_topic_popularity[topic], label=topic)\n",
        "plt.title('Daily Topic Popularity Trends')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Popularity (Mean Engagement)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting weekly topic popularity trends\n",
        "plt.figure(figsize=(15, 6))\n",
        "for topic in topic_keywords.keys():\n",
        "    plt.plot(weekly_topic_popularity['date'], weekly_topic_popularity[topic], label=topic)\n",
        "plt.title('Weekly Topic Popularity Trends')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Popularity (Sum of Daily Means)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GbeB4ahSRQ_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting monthly topic popularity trends\n",
        "plt.figure(figsize=(15, 6))\n",
        "for topic in topic_keywords.keys():\n",
        "    plt.plot(monthly_topic_popularity['date'], monthly_topic_popularity[topic], label=topic)\n",
        "plt.title('Monthly Topic Popularity Trends')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Popularity (Sum of Daily Means)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Generating heatmap of correlation matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix: Engagement vs. Topic Popularity')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3arl4bplT_qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Analysis Key Findings\n",
        "- Daily engagement shows significant fluctuations,\n",
        "- Brand/Product\" and \"User Sentiment\" topic popularity generally exhibit similar daily and weekly patterns.\n",
        "- There is a moderate positive correlation (0.39) between \"user_sentiment\" popularity and engagement count.\n",
        "- There is a moderate negative correlation (-0.40) between \"brand_product\" popularity and engagement count.\n",
        "\n",
        "Insights or Next Steps\n",
        "- Focus on content that emphasizes \"User Sentiment\" (opinions, positive experiences, desired products) as it is most positively correlated with engagement.\n",
        "- Investigate the unexpected negative correlation with \"Brand/Product\" content to understand if the method of presentation (e.g., overly promotional vs. integrated into user stories) impacts engagement.\n"
      ],
      "metadata": {
        "id": "qNFjtlcYSAVQ"
      }
    }
  ]
}