{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment pipeline using langchain"
      ],
      "metadata": {
        "id": "-y-vYpMyaSD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Z-FU4q1OzKdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai > /dev/null\n",
        "!pip install langchain_core > /dev/null"
      ],
      "metadata": {
        "id": "OzpMTOHnbe3t"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts.chat import ChatPromptTemplate\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "from langchain_core.runnables.passthrough import RunnablePassthrough"
      ],
      "metadata": {
        "id": "8adLoKV7am1N"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Creates chain for text classification'''\n",
        "def create_chain():\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        '{text}\\n'\n",
        "        'Is the sentiment positive or negative?\\n'\n",
        "        'Answer (\"Positive\"/\"Negative\")\\n')\n",
        "    llm = ChatOpenAI(\n",
        "        model='gpt-4o', temperature=0,\n",
        "        max_tokens=1)\n",
        "    parser = StrOutputParser()\n",
        "    chain = ({'text':RunnablePassthrough()} | prompt | llm | parser)\n",
        "    return chain\n"
      ],
      "metadata": {
        "id": "nPjBVmgvblBA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('engagements.csv')\n",
        "df,"
      ],
      "metadata": {
        "id": "fvpmulM5b_VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_chain()\n",
        "\n",
        "class_text_result = chain.batch(list(df['comment_text'[:10]]))\n",
        "df['class_text'] = class_text_result\n",
        "df.to_csv('class_text_result.csv')"
      ],
      "metadata": {
        "id": "4FH0YxrRgyAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' process with batch_size '''\n",
        "import time\n",
        "chain = create_chain()\n",
        "batch_size = 100  # Adjust batch size as needed\n",
        "num_batches = (len(df) + batch_size - 1) // batch_size\n",
        "all_results = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_index = i * batch_size\n",
        "    end_index = min((i + 1) * batch_size, len(df))\n",
        "    comment_batch = list(df['comment_text'][start_index:end_index])\n",
        "    batch_results = chain.batch(comment_batch)\n",
        "    all_results.extend(batch_results)\n",
        "    time.sleep(1) # Add a delay between batches\n",
        "\n",
        "df['class_text'] = all_results"
      ],
      "metadata": {
        "id": "GnB9zkQdlCtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('file_path', type=str, help='Path to input .csv file')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    df = pd.read_csv(args.file_path)\n",
        "    chain = create_chain()\n",
        "\n",
        "    class_text_result = chain.batch(list(df['comment_text']))\n",
        "    df['class_text'] = class_text_result\n",
        "    df.to_csv('class_text_result.csv')"
      ],
      "metadata": {
        "id": "lOUjAyFkblRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setiment pipeline with Vertex"
      ],
      "metadata": {
        "id": "B8IV0P2Nh4lv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ab3497a"
      },
      "source": [
        "!pip install google-cloud-aiplatform > /dev/null"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bf58df9"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8de3b835",
        "outputId": "50444e69-3814-4e93-eac4-735862faa4b0"
      },
      "source": [
        "import vertexai\n",
        "\n",
        "PROJECT_ID = 'llm-test-428715'  # Replace with your Google Cloud project ID\n",
        "LOCATION = 'us-central1'  # Replace with your desired Vertex AI location\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "print(f\"Vertex AI initialized for project '{PROJECT_ID}' in location '{LOCATION}'.\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertex AI initialized for project 'llm-test-428715' in location 'us-central1'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db792f2d"
      },
      "source": [
        "from vertexai.language_models import TextGenerationModel\n",
        "# Choose a model suitable for text classification/sentiment analysis\n",
        "# 'text-bison@001' is a good general-purpose text model\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03e6299f"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('engagements.csv')\n",
        "display(df.describe(include='all'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe8aead4"
      },
      "source": [
        "df['vertex_sentiment'].fillna('Unknown', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GitLnRHQop-F"
      },
      "source": [
        "# 1. Define a prompt template string\n",
        "sentiment_prompt_template = \"\"\"\n",
        "Analyze the sentiment of the following text and classify it as either \"Positive\" or \"Negative\".\n",
        "\n",
        "Text: {text}\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "def get_vertex_sentiment(text):\n",
        "    if pd.isna(text):\n",
        "        return None  # Handle missing values\n",
        "    try:\n",
        "        prompt = sentiment_prompt_template.format(text=text)\n",
        "        response = model.predict(prompt)\n",
        "        sentiment = response.text.strip()\n",
        "        if sentiment not in [\"Positive\", \"Negative\"]:\n",
        "             return \"Unknown\" # Or re-try, or log an error\n",
        "        return sentiment\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {text[:50]}... Error: {e}\")\n",
        "        return \"Error\" # Handle potential errors during prediction\n",
        "\n",
        "df['vertex_sentiment'] = df['comment_text'].head(100).apply(get_vertex_sentiment)\n",
        "df['vertex_sentiment'].fillna('Unknown', inplace=True)\n",
        "display(df[['comment_text', 'vertex_sentiment']].head())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}